\chapter{РАЗРАБОТКА МОДУЛЕЙ}
% \chapter{Разработка модулей}

\section{Выбор стека технологий}

Перед началом реализации разработанной архитектуры необходимо выбрать
стек технологий, которые будут использоваться при разработке.
Необходимо определиться со следующими пунктами:
\begin{itemize}
    \item операционная система
    \item гипервизоры
    \item реализация управляющей логики
    \item API
\end{itemize}
Касательно гипервизоров, необходимо выбрать способ виртуализации обычных виртуальных машин
и сетевого оборудования.

В качестве операционной системы предпочтительнее всего использовать Linux, так как ее 
администрирование не представляет собой большой проблемы, она бесплатна и имеет
открытый исходный код и отличную поддержку большинства современных языков 
программирования. Кроме этого, для администрирования Linux существуют доказавшие
свою эффективность системы автоматизации установки и администрирования, что совершенно
необходимо для успешной поддержки многомашинных систем.
%TODO источники

Если говорить о виртуализации сетевого оборудования, то имеется два пути: использовать
специализированные гипервизоры, или же использовать стандартные гипервизоры вместе с
программными коммутаторами, такими как Open vSwitch. На текущий момент, программные
коммутаторы редко используются при создании сетей в предприятиях, поэтому большого
смысла поддерживать этот вариант нет. По данным Infonetics Research, Cisco занимает
лидирующие позиции на рынке сетевого оборудования,
% http://www.infonetics.com/pr/2012/3Q12-Service-Provider-Routers-Switches-Market-Highlights.asp
поэтому выбор этого сетевого оборудования в качестве цели для виртуализации вполне оправдан.
Кроме этого, гипервизор dynamips, предназначенный для эмуляции именно этого оборудования,
является самым распространенным и стабильным в своей области. %TODO источник

Среди гипервизоров PC-совместмого оборудования можно выделить несколько наиболее
популярных решений для Linux:
\begin{itemize}
    \item VmWare ESX
    \item VirtualBox
    \item Xen
    \item KVM
\end{itemize}

VmWare ESX является одним из наиболее популярных коммерческих гипервизоров, но при 
использовании в рамках данного проекта имеет ряд недостатков. Во-первых, гипервизор
работает только со специальным образом модифицированным ядром ОС, во-вторых,
данный гипервизор имеет закрытый код, и в случае необходимости становится невозможным
внести изменения, необходимые для реализации проекта.

VirtualBox -- гипервизор с открытым исходным кодом, в данный момент поддерживаемый 
компанией Oracle. Данный продукт в основном базируется как решение для настольных
компьютеров, несмотря на возможность работы без графического интерфейса.
Ранее VirtualBox разрабатывался компанией Sun, которая была куплена Oracle в 2010 году.
Переход многих программ с открытым исходным кодом во владение к Oracle сказался на
их поддержке крайне негативно, поэтому в долгосрочной перспективе использование
VirtualBox при реализации данного проекта не имеет большого смысла при наличии альтернатив.

Xen долгое время был выбором по-умолчанию в Linux-среде и активно поддерживался
самой большой Linux-компанией -- RedHat. %TODO источник
Тем не менее, последние несколько лет интерес к нему падает, так как
RedHat переключил свой фокус на KVM. Так же, в силу того, что этот гипервизор 
использует технику паравиртуализации, его администрирование имеет ряд отличий
от администрирования обычных Linux-систем.

KVM -- относительно новый, но уже достаточно популярный и стабильный Linux-специфичный
гипервизор. На данный момент он активно поддерживается, в том числе коммерческими компаниями,
такими как RedHat, и на настоящий момент является выбором по-умолчанию для виртуализации в 
Linux. Кроме этого, благодаря открытому коду, в него будет возможно внести изменения,
если такая необходимость возникнет во время разработки.
Таким образом, в качестве гипервизора PC-совместимых виртуальных машин в данном проекте
будет использоваться KVM.

При разработка управляющей логики имеется два варианта: писать весь необходимый код с нуля, 
используя только стандартные библиотеки языков, или же расширить возможности имеющейся
платформы. Написание кода с нуля с одной стороны позволяет получить полный контроль 
над кодовой базой и выбором технологий, но с другой стороны -- потребует реализации
большого объема относительно стандартной логики, которая не имеет большого отношения 
к сути данной работы. Гораздо более оптимальным вариантом является использование уже 
существующих наработок.

Как нельзя кстати в данном случае подходит платформа OpenStack. Рассматривая компоненты,
из которых она состоит, можно отметить, что архитектура этой платформы хорошо вписывается
в архитектуру, разработанную в предыдущей главе. Соответствие компонент OpenStack и 
предполагаемых компонент платформы моделирования сети можно увидеть на рис.~\ref{fig:openstack-lowlevel}.
\begin{figure}
  \centering
  {\footnotesize\input{fig/openstack-lowlevel}}
  \caption{Соответствие архитектуры OpenStack и архитектуры системы моделирования топологий}  
  \label{fig:openstack-lowlevel}
\end{figure}
Очевидно, что большинство компонент OpenStack может быть использовано в 
системе моделирования сетей либо напрямую, без всякой модификации, либо путем
написания соответствующего расширяющего кода. Список компонентов, подлежащих
повторному использованию, представлен в таблице~\ref{tab:openstack-reuse}
\begin{table}
\center
\caption{Возможность посторного использования компонент OpenStack}
\label{tab:openstack-reuse}
\begin{tabular}{|p{5cm}|p{4cm}|p{5cm}|} \hline 
\multicolumn{3}{|c|}{подсистема прикладного программного интерфейса} \\ \hline 
авторизация и аутентификация & quantum & без изменений\\ \hline
логика высокоуровневых команд & - & необходима реализация \\ \hline
\multicolumn{3}{|c|}{подсистема хранения данных} \\ \hline
хранение образов ОС & glance & без изменений \\ \hline
хранение данных виртуальных машин & на узлах nova-compute или в nova-volume & без изменений\\ \hline
\multicolumn{3}{|c|}{вычислительная подсистема} \\ \hline
подсистема планировки ресурсов & nova-scheduler & без изменений \\ \hline
подсистема сетевого взаимодействия & quantum & необходим дополнительный модуль \\ \hline
подсистема виртуализации & nova-compute & необходим дополнительный модуль \\ \hline
\hline 
\end{tabular} 
\end{table}

Путем использования уже существующей платформы, при реализации системы моделирования
сетей мы избегаем реализации большого количества не относящейся к сути логики. В итоге мы
получаем три основных модуля, требующих реализации:
\begin{enumerate}
    \item высокоуровневый прикладной программный интерфейс
    \item сетевое взаимодействие
    \item запуск специфических виртуальных машин -- маршрутизаторов в гипервизоре dynamips
\end{enumerate}

Прикладной программный интерфейс должен работать в терминах разработанной модели данных.
Следуя концепции модульной архитектуры, он будет реализован в виде отдельного процесса,
и будет транслировать высокоуровневые вызовы пользователя в ряд вызовов к нижележащим
подсистемам: nova-api и quantum.
%TODO технологии?

Модель сети, которая используется внутри OpenStack по-умолчанию устроена так, что 
все виртуальные машины одного проекта находятся в одной подсети. Тем не менее,
используя последние наработки сообщества разработчиков этой платформы, возможно использование
quantum для гибкой настройки соединения между виртуальными машинами.

Для того, чтобы конфигурировать сеть между виртуальными машинами в OpenStack на 
канальном уровне, необходимо реализовать два аспекта. Во-первых, необходим такой способ 
инкапсуляции кадров канального уровня, который позволит запускать достаточно большое
количество виртуальных машин в одной системе, обеспечивая изоляцию между ними.
Во вторых, необходимо предоставлять данные о физических портах в подсистему виртуализации.

Проекты GNS3 и dynagen решают проблему инкапсуляции при помощи использования UDP-каналов.
Для работы dynamips совместно с KVM при данном подходе ранее было необходимо использование 
специально модифицированной версии Qemu, но на настоящий момент UDP-каналы
поддерживаются и в официальной версии эмулятора.

Проблема предоставления данных о физических портах в систему виртуализации вытекает
из ограниченной сетевой модели OpenStack, которая использовалась с самого начала разработки
проекта. Вместо явного указания количества виртуальных сетевых адаптеров и способа их 
соединения с сетями, в nova-compute передавался только список сетей, к которым необходимо
подключить виртуальную машину. По этой причине не существует стандартного способа передачи
таких метаданных о подключенной сети, как номер сетевой карты и порта.
Для решения проблемы метаданных портов в рамках этого проекта создано расширение прикладного 
программного интерфейса Quantum, позволяющее задавать и получать метаданные порта.

Архитектура nova-compute изначально была расчитана на поддержку различных гипервизоров.
Благодаря этому, для поддержки виртуализации сетевого оборудования системой моделирования
сетей, необходимо создать так называемый драйвер гипервизора. Интерфейс драйвера гипервизора
содержит около 60 методов, из которых далеко не все обязательны для реализации, и
в нашем случае задача сводится к созданию простой обертки над dynagen, которая конфигурирует
виртуальные маршрутизаторы согласно информации, полученной от прикладного программного
интерфейса и расширения Quantum для метаданных.

\section{Описание прикладного программного интерфейса}
TBD

\section{Физическая топология}
TBD

\section{Реализация прикладной программного интерфейса}
TBD

\section{Подсистема прикладного программного интерфейса}
TBD

\section{Подсистема сетевого взаимодействия}
TBD

\section{Подсистема виртуализации}
TBD

